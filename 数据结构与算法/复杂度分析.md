#复杂度分析

[TOC]

- 复杂度分析主要是指**时间、空间复杂度分析。**

##为什么需要复杂度分析?

- **事后统计法**:通过统计、监控就能得到算法执行时间和占用的内存大小。
- 为什么有了事后统计法还需要复杂度分析？因为统计方法的局限性：
 - 1.测试结构非常依赖测试环境，不同的硬件对测试结果有很大的影响。
 - 2.数据规模的影响很大，测试结果无法真实反映算法的性能。

##大O复杂度表示法

- **时间、空间复杂度分析法**：不用具体的测试数据测试，就可以粗略的估计算法的执行效率的方法。

###T(n)= O(f(n))

- **所以代码的执行时间T(n)与每行代码的执行次数n成正比。**
- 上面公式T(n)代表代码执行的总时间;n表示数据规模的大小;f(n)表示每行代码执行的次数总和。O代表代码的执行时间T(n)与f(n)表达式成正比。
- 比方说T(n)=O(2n+2)就是大O时间复杂度表示法。
- **大O时间复杂度**实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随着数据规模增长的变化趋势**，所以，也叫**渐进时间复杂度**（asymptotic time complexity）,简称**时间复杂度**。
- 当n很大是，公式中的低阶、常量、系数三部分并不左右增长的趋势，所以可以忽略。

####时间复杂度

1.**分析一个算法、一段代码的时间复杂度的时候，只关注循环执行次数最多的那一段代码就可以了。**
2.**加法法则：总复杂度等于量级最大的那段代码的复杂度。**
3.**乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。**

- 四个复杂度分析方面的知识点：**最好情况时间复杂度（best case time complexity）、最坏情况时间复杂度（worst case time complexity）、平均情况时间复杂度（average case time complexity）、均摊时间复杂度（amortized time complexity）。**
 - **最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。**
 - **最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。**
 - **平均复杂度的值是概率论中的加权平均值，也叫做期望值，平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。**
 - **均摊时间复杂度**就是对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在连贯的时序关系，我们把这组操作复杂度较高的均摊到复杂度较低的操作上。一般均摊时间复杂度就等于最好情况时间复杂度。

- 几种常见的多项式时间复杂度分析
> O(n！)这种非多项式时间会无线增长，所以不分析

#####1.O(1)

- **只要算法不存在循环语句、递归语句，即使有成千上万行代码，其时间复杂度也是O(1)。**

#####O(logn).O(nlogn)
- 对数阶时间复杂度是常见的一种时间复杂度，如：

```java
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```
上述代码的时间复杂度就是O(log2^n),**不管对数阶的时间复杂度底数是多少，都记为O(logn)**，因为对数的底数可以提取出来称为一个常量。

#####O(m+n)、O(m*n)

- 复杂度由**两个数据的规模**来决定。

####空间复杂度分析

- 空间复杂度全称就是**渐进空间复杂度**（asymptotic space complexity）,**表示算法的存储空间与数据规模之间的增长关系**。
- 常见的空间复杂度就是O(1)、O(n)、O(2^n)
- 空间复杂度是指除了原本的数据存储空间外，算法运行还需要额外的存储空间


